{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = \"./data\"\n",
    "PATH_COCORDIAIS = \"./cocordiais\"\n",
    "\n",
    "IMAGES_METFACES = os.path.join(PATH_DATASET, \"metfaces-source\")\n",
    "IMAGES_CORDIAIS = os.path.join(PATH_DATASET, \"cordiais-source\")\n",
    "\n",
    "JSON_METFACES = os.path.join(PATH_DATASET, \"metfaces.json\")\n",
    "JSON_CORDIAIS = os.path.join(PATH_DATASET, \"cordiais.json\")\n",
    "\n",
    "FILES_METFACES = sorted([f.replace(\".jpg\", \"\") for f in os.listdir(IMAGES_METFACES) if f.endswith(\".jpg\")])\n",
    "FILES_CORDIAIS = sorted([f.replace(\".jpg\", \"\") for f in os.listdir(IMAGES_CORDIAIS) if f.endswith(\".jpg\")])\n",
    "\n",
    "random.seed(101010)\n",
    "shuffled_cordiais = random.sample(FILES_CORDIAIS, k=len(FILES_CORDIAIS))\n",
    "shuffled_metfaces = random.sample(FILES_METFACES, k=len(FILES_METFACES))\n",
    "\n",
    "INITIAL_DATASETS = [\n",
    "  {\n",
    "    \"name\": \"cordiais\",\n",
    "    \"license_id\": 1,\n",
    "    \"date\": \"2023-06-10 00:00:00\",\n",
    "    \"splits\": {\n",
    "      \"test\": shuffled_cordiais[int(0.5 * len(FILES_CORDIAIS)):],\n",
    "      \"train\": shuffled_cordiais[int(0.1 * len(FILES_CORDIAIS)) : int(0.5 * len(FILES_CORDIAIS))],\n",
    "      \"validation\": shuffled_cordiais[:int(0.1 * len(FILES_CORDIAIS))]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"metfaces\",\n",
    "    \"license_id\": 1,\n",
    "    \"date\": \"2020-06-10 00:00:00\",\n",
    "    \"splits\": {\n",
    "      \"test\": [],\n",
    "      \"train\": shuffled_metfaces[int(0.2 * len(FILES_METFACES)):],\n",
    "      \"validation\": shuffled_metfaces[:int(0.2 * len(FILES_METFACES))]\n",
    "    }\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy files to cocordiais directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in INITIAL_DATASETS:\n",
    "  for split in dset[\"splits\"].keys():\n",
    "    for fn in dset[\"splits\"][split]:\n",
    "      shutil.copy2(\n",
    "        os.path.join(PATH_DATASET, \"%s-source\" % dset[\"name\"], \"%s.jpg\" % fn),\n",
    "        os.path.join(PATH_COCORDIAIS, split)\n",
    "      )\n",
    "\n",
    "shutil.copy2(\n",
    "  os.path.join(PATH_DATASET, \"id2label.json\"),\n",
    "  os.path.join(PATH_COCORDIAIS)\n",
    ")\n",
    "\n",
    "shutil.copy2(\n",
    "  os.path.join(PATH_DATASET, \"label2id.json\"),\n",
    "  os.path.join(PATH_COCORDIAIS)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocordiais_dataset = {\n",
    "  \"info\": {\n",
    "    \"year\": 2023,\n",
    "    \"version\": \"1.0\",\n",
    "    \"description\": \"Object Detection dataset to detect female-ish faces in paintings\",\n",
    "    \"contributor\": \"Thiago Hersan\",\n",
    "    \"url\": \"https://huggingface.co/thiagohersan\",\n",
    "    \"date_created\": \"%s\" % datetime.datetime.now(),\n",
    "  },\n",
    "  \"categories\": [\n",
    "    { \"id\": 0, \"name\": \"N/A\", \"supercategory\": \"N/A\", },\n",
    "    { \"id\": 1, \"name\": \"female\", \"supercategory\": \"face\", },\n",
    "    { \"id\": 2, \"name\": \"not-female\", \"supercategory\": \"face\", },\n",
    "  ],\n",
    "  \"licenses\": [\n",
    "    { \"id\": 1, \"name\": \"CC BY-NC 2.0\", \"url\": \"https://creativecommons.org/licenses/by-nc/2.0/\", },\n",
    "    { \"id\": 2, \"name\": \"CC0 1.0\", \"url\": \"https://creativecommons.org/publicdomain/zero/1.0/\", },\n",
    "  ],\n",
    "  \"images\": [],\n",
    "  \"annotations\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this could be a class... maybe ?\n",
    "files = {}\n",
    "img2id = {}\n",
    "id2img = {}\n",
    "coco_annotations = {}\n",
    "\n",
    "for s in [\"test\", \"train\", \"validation\"]:\n",
    "  split_dir = os.path.join(PATH_COCORDIAIS, s)\n",
    "  split_file_list = sorted([f.replace(\".jpg\", \"\") for f in os.listdir(split_dir) if f.endswith(\".jpg\")])\n",
    "  files[s] = set(split_file_list)\n",
    "  img2id[s] = {f: i for i,f in enumerate(split_file_list)}\n",
    "  id2img[s] = {}\n",
    "  coco_annotations[s] = []\n",
    "\n",
    "\n",
    "def get_split(fn):\n",
    "  for s in [\"test\", \"train\", \"validation\"]:\n",
    "    if fn in files[s]:\n",
    "      return s\n",
    "\n",
    "\n",
    "for dset in INITIAL_DATASETS:\n",
    "  dset_name = dset[\"name\"]\n",
    "  dataset_path_in = os.path.join(PATH_DATASET, \"%s.json\" % dset_name)\n",
    "\n",
    "  with open(dataset_path_in) as json_file_in:\n",
    "    data = json.load(json_file_in)\n",
    "    for obj in data:\n",
    "      my_split = get_split(obj[\"source_image\"])\n",
    "      my_img_id = img2id[my_split][obj[\"source_image\"]]\n",
    "\n",
    "      id2img[my_split][my_img_id] = {\n",
    "        \"id\": my_img_id,\n",
    "        \"width\": obj[\"source_image_w\"],\n",
    "        \"height\": obj[\"source_image_h\"],\n",
    "        \"file_name\": \"%s.jpg\" % obj[\"source_image\"],\n",
    "        \"license\": dset[\"license_id\"],\n",
    "        \"date_captured\": dset[\"date\"],\n",
    "        \"coco_url\": \"\",\n",
    "        \"flickr_url\": \"\"\n",
    "      }\n",
    "\n",
    "      poly = [\n",
    "        [obj[\"face_rect_xyxy\"][0], obj[\"face_rect_xyxy\"][1]],\n",
    "        [obj[\"face_rect_xyxy\"][2], obj[\"face_rect_xyxy\"][1]],\n",
    "        [obj[\"face_rect_xyxy\"][2], obj[\"face_rect_xyxy\"][3]],\n",
    "        [obj[\"face_rect_xyxy\"][0], obj[\"face_rect_xyxy\"][3]]\n",
    "      ]\n",
    "\n",
    "      ann_obj = {\n",
    "        \"id\": len(coco_annotations[my_split]),\n",
    "        \"image_id\": my_img_id,\n",
    "        \"category_id\": obj[\"gender\"],\n",
    "        \"segmentation\": list([poly]),\n",
    "        \"area\": obj[\"face_rect_xywh\"][2] * obj[\"face_rect_xywh\"][3],\n",
    "        \"bbox\": obj[\"face_rect_xywh\"],\n",
    "        \"iscrowd\": 0,\n",
    "      }\n",
    "\n",
    "      coco_annotations[my_split].append(ann_obj)\n",
    "\n",
    "for s in [\"test\", \"train\", \"validation\"]:\n",
    "  coco_split = json.loads(json.dumps(cocordiais_dataset))\n",
    "  coco_split[\"images\"] = list(id2img[s].values())\n",
    "  coco_split[\"annotations\"] = list(coco_annotations[s])\n",
    "\n",
    "  out_file = os.path.join(PATH_COCORDIAIS, s, \"cocordiais.json\")\n",
    "\n",
    "  with open(out_file, 'w') as json_file_out_write:\n",
    "    json.dump(coco_split, json_file_out_write)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check jsons, images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import DetrImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "  def __init__(self, img_folder, processor, train=True):\n",
    "    ann_file = os.path.join(img_folder, \"cocordiais.json\")\n",
    "    super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "    self.processor = processor\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # read in PIL image and target in COCO format\n",
    "    # feel free to add data augmentation here before passing them to the next step\n",
    "    img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "    \n",
    "    # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "    image_id = self.ids[idx]\n",
    "    target = {'image_id': image_id, 'annotations': target}\n",
    "    encoding = self.processor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "    pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "    target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "    return pixel_values, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "train_dataset = CocoDetection(img_folder='./cocordiais/train', processor=processor)\n",
    "val_dataset = CocoDetection(img_folder='./cocordiais/validation', processor=processor, train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = train_dataset.coco.getImgIds()\n",
    "image_id = 2\n",
    "image_id = 3\n",
    "image_id = random.randint(0, len(image_ids))\n",
    "\n",
    "image = train_dataset.coco.loadImgs(image_id)[0]\n",
    "image = Image.open(os.path.join('./cocordiais/train', image['file_name']))\n",
    "\n",
    "annotations = train_dataset.coco.imgToAnns[image_id]\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "cats = train_dataset.coco.cats\n",
    "id2label = {k: v['name'] for k,v in cats.items()}\n",
    "\n",
    "for annotation in annotations:\n",
    "  label = id2label[annotation['category_id']]\n",
    "  x,y,w,h = tuple(annotation['bbox'])\n",
    "  draw.rectangle((x,y,x+w,y+h), outline='red', width=2)\n",
    "  draw.text((x, y), label, fill='white')\n",
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
