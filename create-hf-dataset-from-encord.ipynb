{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cocordiais import CocordiaisUtils as cocordiais\n",
    "\n",
    "from random import sample\n",
    "from shutil import copy2\n",
    "\n",
    "import datasets\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "\n",
    "IMG_DIRS = [\n",
    "  \"baoat-source\",\n",
    "  \"cordiais-source\",\n",
    "  \"hermitage-source\"\n",
    "]\n",
    "\n",
    "COCO_JSON_PATH = os.path.join(DATA_PATH, \"encord-coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse images from json, add real path/source name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COCO_JSON_PATH) as json_file_read:\n",
    "  coco_json = json.load(json_file_read)\n",
    "\n",
    "id2image = {}\n",
    "source2images = {src: [] for src in IMG_DIRS}\n",
    "\n",
    "for img in coco_json[\"images\"]:\n",
    "  img[\"file_name\"] = img[\"image_title\"]\n",
    "  del img[\"coco_url\"]\n",
    "  del img[\"image_title\"]\n",
    "\n",
    "  for ds in IMG_DIRS:\n",
    "    if os.path.isfile(os.path.join(DATA_PATH, ds, img[\"file_name\"])):\n",
    "      img[\"source\"] = ds\n",
    "      if not os.path.isfile(os.path.join(DATA_PATH, \"encord-source\", img[\"file_name\"])):\n",
    "        copy2(os.path.join(DATA_PATH, ds, img[\"file_name\"]), os.path.join(DATA_PATH, \"encord-source\"))\n",
    "      break\n",
    "\n",
    "  source2images[img[\"source\"]].append(img[\"file_name\"])\n",
    "  id2image[img[\"id\"]] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordiais_files = source2images[\"cordiais-source\"]\n",
    "test_size = int(0.5 * len(cordiais_files))\n",
    "test_images = cordiais_files[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug2obj = {}\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "  slug2obj[split] = {}\n",
    "\n",
    "for object_info in coco_json[\"annotations\"]:\n",
    "  img_info = id2image[object_info[\"image_id\"]]\n",
    "  file_name = img_info[\"file_name\"]\n",
    "  object_split = \"test\" if file_name in test_images else \"train\"\n",
    "\n",
    "  if file_name not in slug2obj[object_split]:\n",
    "    slug2obj[object_split][file_name] = {\n",
    "      \"image_id\": object_info[\"image_id\"],\n",
    "      \"image\": os.path.join(DATA_PATH, \"encord-source\", file_name),\n",
    "      \"image_filename\": file_name,\n",
    "      \"width\": img_info[\"width\"],\n",
    "      \"height\": img_info[\"height\"],\n",
    "      \"objects\": []\n",
    "    }\n",
    "\n",
    "  slug2obj[object_split][file_name][\"objects\"].append({\n",
    "    \"bbox_id\": object_info[\"id\"],\n",
    "    \"area\": object_info[\"area\"],\n",
    "    \"bbox\": object_info[\"bbox\"],\n",
    "    \"category\": cocordiais.ID2LABEL[object_info[\"category_id\"]],\n",
    "    \"super_category\": cocordiais.ID2SUPERLABEL[object_info[\"category_id\"]],\n",
    "    \"is_crowd\": object_info[\"iscrowd\"]\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug2obj[\"test\"][\"alberto-da-veiga-guignard_lea-e-maura.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {}\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "  records = json.loads(json.dumps(list(slug2obj[split].values())))\n",
    "  for r in records:\n",
    "    r[\"objects\"] = pd.DataFrame(r[\"objects\"]).to_dict(\"list\")\n",
    "  ds_dict[split] = pd.DataFrame(records).to_dict(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.DatasetDict({\n",
    "  split: datasets.Dataset.from_dict(data, features=cocordiais.COCORDIAIS_FEATURES, info=cocordiais.get_dataset_info(), split=split) for split, data in ds_dict.items()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_DATASET = \"thiagohersan/cordiais-encord-faces\"\n",
    "hf_dataset.push_to_hub(HF_DATASET, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch import ones_like\n",
    "from transformers import DetrImageProcessor\n",
    "\n",
    "from Cocordiais import CocordiaisDataset, CocordiaisUtils\n",
    "\n",
    "try:\n",
    "  HF_DATASET = HF_DATASET\n",
    "except NameError:\n",
    "  HF_DATASET = \"thiagohersan/cordiais-encord-faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETR_MODEL = \"facebook/detr-resnet-50\"\n",
    "\n",
    "detr_size = { \"shortest_edge\": 800, \"longest_edge\": 800 }\n",
    "detr_processor = DetrImageProcessor.from_pretrained(DETR_MODEL, size=detr_size)\n",
    "\n",
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset_train = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "dataset_train = CocordiaisDataset(hf_dataset_train[\"train\"], img_processor=detr_processor, train=True)\n",
    "dataset_eval = CocordiaisDataset(hf_dataset_train[\"test\"], img_processor=detr_processor, train=False)\n",
    "dataset_test = CocordiaisDataset(hf_dataset[\"test\"], img_processor=detr_processor, train=False)\n",
    "\n",
    "lens = (len(dataset_train), len(dataset_eval), len(dataset_test))\n",
    "\n",
    "print(\"Number of examples:\\n  Train: %s\\n  Evaluation: %s\\n  Test: %s\" % lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_train.data[idx]\n",
    "img = T.ToPILImage()(data[\"pixel_values\"])\n",
    "# img = hf_dataset_train[\"train\"][idx][\"image\"]\n",
    "\n",
    "boxes_info = {\n",
    "  \"scores\": ones_like(data[\"labels\"][\"class_labels\"]),\n",
    "  \"labels\": data[\"labels\"][\"class_labels\"],\n",
    "  \"boxes\": CocordiaisUtils.bboxes_xcycwh_to_xyxy(data[\"labels\"])\n",
    "}\n",
    "\n",
    "CocordiaisUtils.plot_boxes(img, boxes_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
