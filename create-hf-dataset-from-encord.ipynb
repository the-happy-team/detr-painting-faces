{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cocordiais import CocordiaisUtils as cocordiais\n",
    "\n",
    "from random import sample\n",
    "from shutil import copy2\n",
    "\n",
    "import datasets\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "\n",
    "IMG_DIRS = [\n",
    "  \"baoat-source\",\n",
    "  \"cordiais-source\",\n",
    "  \"hermitage-source\"\n",
    "]\n",
    "\n",
    "COCO_JSON_PATH = os.path.join(DATA_PATH, \"encord-coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse images from json, add real path/source name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COCO_JSON_PATH) as json_file_read:\n",
    "  coco_json = json.load(json_file_read)\n",
    "\n",
    "id2image = {}\n",
    "source2images = {src: [] for src in IMG_DIRS}\n",
    "\n",
    "for img in coco_json[\"images\"]:\n",
    "  img[\"file_name\"] = img[\"image_title\"]\n",
    "  del img[\"coco_url\"]\n",
    "  del img[\"image_title\"]\n",
    "\n",
    "  for ds in IMG_DIRS:\n",
    "    if os.path.isfile(os.path.join(DATA_PATH, ds, img[\"file_name\"])):\n",
    "      img[\"source\"] = ds\n",
    "      if not os.path.isfile(os.path.join(DATA_PATH, \"encord-source\", img[\"file_name\"])):\n",
    "        copy2(os.path.join(DATA_PATH, ds, img[\"file_name\"]), os.path.join(DATA_PATH, \"encord-source\"))\n",
    "      break\n",
    "\n",
    "  source2images[img[\"source\"]].append(img[\"file_name\"])\n",
    "  id2image[img[\"id\"]] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordiais_files = source2images[\"cordiais-source\"]\n",
    "test_size = int(0.5 * len(cordiais_files))\n",
    "test_images = cordiais_files[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug2obj = {}\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "  slug2obj[split] = {}\n",
    "\n",
    "for object_info in coco_json[\"annotations\"]:\n",
    "  img_info = id2image[object_info[\"image_id\"]]\n",
    "  file_name = img_info[\"file_name\"]\n",
    "  object_split = \"test\" if file_name in test_images else \"train\"\n",
    "\n",
    "  if file_name not in slug2obj[object_split]:\n",
    "    slug2obj[object_split][file_name] = {\n",
    "      \"image_id\": object_info[\"image_id\"],\n",
    "      \"image\": os.path.join(DATA_PATH, img_info[\"source\"], file_name),\n",
    "      \"image_filename\": file_name,\n",
    "      \"width\": img_info[\"width\"],\n",
    "      \"height\": img_info[\"height\"],\n",
    "      \"objects\": []\n",
    "    }\n",
    "\n",
    "  slug2obj[object_split][file_name][\"objects\"].append({\n",
    "    \"bbox_id\": object_info[\"id\"],\n",
    "    \"area\": object_info[\"area\"],\n",
    "    \"bbox\": object_info[\"bbox\"],\n",
    "    \"category\": cocordiais.ID2LABEL[object_info[\"category_id\"]],\n",
    "    \"super_category\": cocordiais.ID2SUPERLABEL[object_info[\"category_id\"]],\n",
    "    \"is_crowd\": object_info[\"iscrowd\"]\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug2obj[\"test\"][\"alberto-da-veiga-guignard_lea-e-maura.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {}\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "  records = json.loads(json.dumps(list(slug2obj[split].values())))\n",
    "  for r in records:\n",
    "    r[\"objects\"] = pd.DataFrame(r[\"objects\"]).to_dict(\"list\")\n",
    "  ds_dict[split] = pd.DataFrame(records).to_dict(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.DatasetDict({\n",
    "  split: datasets.Dataset.from_dict(data, features=cocordiais.COCORDIAIS_FEATURES, info=cocordiais.get_dataset_info(), split=split) for split, data in ds_dict.items()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_DATASET = \"thiagohersan/cordiais-encord-faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset.push_to_hub(HF_DATASET, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DetrImageProcessor\n",
    "\n",
    "from Cocordiais import CocordiaisDataset\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETR_MODEL = \"facebook/detr-resnet-50\"\n",
    "\n",
    "detr_size = { \"shortest_edge\": 800, \"longest_edge\": 800 }\n",
    "detr_processor = DetrImageProcessor.from_pretrained(DETR_MODEL, size=detr_size)\n",
    "\n",
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset_train = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "dataset_train = CocordiaisDataset(hf_dataset_train[\"train\"], img_processor=detr_processor, train=True)\n",
    "dataset_eval = CocordiaisDataset(hf_dataset_train[\"test\"], img_processor=detr_processor, train=False)\n",
    "dataset_test = CocordiaisDataset(hf_dataset[\"test\"], img_processor=detr_processor, train=False)\n",
    "\n",
    "lens = (len(dataset_train), len(dataset_eval), len(dataset_test))\n",
    "\n",
    "print(\"Number of examples:\\n  Train: %s\\n  Evaluation: %s\\n  Test: %s\" % lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "  dataset_train.data,\n",
    "  collate_fn=dataset_train.collate_batch,\n",
    "  batch_size=12,\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_eval = DataLoader(\n",
    "  dataset_eval.data,\n",
    "  collate_fn=dataset_eval.collate_batch,\n",
    "  batch_size=4,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "  dataset_test.data,\n",
    "  collate_fn=dataset_test.collate_batch,\n",
    "  batch_size=4,\n",
    "  shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "d_train = dataset_train.data[idx]\n",
    "# img_train = T.ToPILImage()(d_train[\"pixel_values\"])\n",
    "img_train = hf_dataset_train[\"train\"][idx][\"image\"]\n",
    "img_w, img_h = img_train.size\n",
    "\n",
    "annotations = d_train[\"labels\"]\n",
    "draw = ImageDraw.Draw(img_train, \"RGBA\")\n",
    "\n",
    "id2label = {0:\"female\", 1:\"not-female\"}\n",
    "id2label = hf_dataset[\"train\"].features[\"objects\"].feature[\"category\"].names\n",
    "\n",
    "for i in range(len(annotations[\"boxes\"])):\n",
    "  label = id2label[annotations[\"class_labels\"][i].item()]\n",
    "  xc,yc,w,h = tuple(annotations[\"boxes\"][i])\n",
    "  draw.rectangle(((xc-w/2)*img_w, (yc-h/2)*img_h, (xc+w/2)*img_w, (yc+h/2)*img_h), outline=\"red\", width=2)\n",
    "  draw.text(((xc-w/2)*img_w, (yc-h/2)*img_h), label, fill=\"white\")\n",
    "img_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
