{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune DETR to detect female-ish faces in paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade scipy transformers datasets huggingface_hub pytorch-lightning pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "from Cocordiais import CocordiaisDataset, CocordiaisUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from HF and turn to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUXILIARY_LOSS = False\n",
    "CLASS_COST = 1\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "aux_string = \"-aux\" if AUXILIARY_LOSS else \"\"\n",
    "cc_string = (\"-cc%s\" % CLASS_COST) if CLASS_COST > 1 else \"\"\n",
    "\n",
    "DETR_MODEL = \"facebook/detr-resnet-50\"\n",
    "HF_DATASET = \"thiagohersan/cordiais-faces\"\n",
    "HF_MODEL = f\"thiagohersan/detr-cordiais-aug2-{NUM_EPOCHS}{aux_string}{cc_string}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_size = { \"shortest_edge\": 800, \"longest_edge\": 800 }\n",
    "detr_processor = DetrImageProcessor.from_pretrained(DETR_MODEL, size=detr_size)\n",
    "\n",
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "dataset_train = CocordiaisDataset(hf_dataset[\"train\"], img_processor=detr_processor, train=True)\n",
    "dataset_eval = CocordiaisDataset(hf_dataset[\"test\"], img_processor=detr_processor, train=False)\n",
    "\n",
    "print(\"Number of examples:\\n  Train: %s\\n  Evaluation: %s\" % (len(dataset_train), len(dataset_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "  dataset_train.data,\n",
    "  collate_fn=dataset_train.collate_batch,\n",
    "  batch_size=12,\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_eval = DataLoader(\n",
    "  dataset_eval.data,\n",
    "  collate_fn=dataset_eval.collate_batch,\n",
    "  batch_size=4,\n",
    "  shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "pixel_values, _, target = dataset_train.data[0].values()\n",
    "print(pixel_values.shape)\n",
    "print(target)\n",
    "\n",
    "batch = next(iter(dataloader_train))\n",
    "print(batch.keys())\n",
    "pimg = ToPILImage()(batch[\"pixel_values\"][0])\n",
    "print(pimg.size)\n",
    "pimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with PyTorchLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detr(LightningModule):\n",
    "  def __init__(self, dl_train, dl_eval, lr, lr_backbone, weight_decay):\n",
    "    super().__init__()\n",
    "    # replace COCO classification head with custom head\n",
    "    self.model = DetrForObjectDetection.from_pretrained(\n",
    "      DETR_MODEL,\n",
    "      revision=\"no_timm\",\n",
    "      num_labels=len(CocordiaisUtils.ID2LABEL),\n",
    "      num_queries=16,\n",
    "      ignore_mismatched_sizes=True,\n",
    "      auxiliary_loss=AUXILIARY_LOSS,\n",
    "      class_cost=CLASS_COST\n",
    "    )\n",
    "\n",
    "    self.lr = lr\n",
    "    self.lr_backbone = lr_backbone\n",
    "    self.weight_decay = weight_decay\n",
    "\n",
    "    self.dataloader_train = dl_train\n",
    "    self.dataloader_eval = dl_eval\n",
    "    self.batch_size_train = dl_train.batch_size\n",
    "    self.batch_size_eval = dl_eval.batch_size\n",
    "\n",
    "  def forward(self, pixel_values, pixel_mask):\n",
    "    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "    return outputs\n",
    "\n",
    "  def common_step(self, batch, batch_idx):\n",
    "    pixel_values = batch[\"pixel_values\"]\n",
    "    pixel_mask = batch[\"pixel_mask\"]\n",
    "    labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss_dict = outputs.loss_dict\n",
    "\n",
    "    return loss, loss_dict\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    self.log(\"training_loss\", loss, batch_size=self.batch_size_train)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"training_\" + k, v.item(), batch_size=self.batch_size_train)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)     \n",
    "    self.log(\"validation_loss\", loss, batch_size=self.batch_size_eval)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"validation_\" + k, v.item(), batch_size=self.batch_size_eval)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    param_dicts = [\n",
    "      {\n",
    "        \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]\n",
    "      },\n",
    "      {\n",
    "        \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "        \"lr\": self.lr_backbone,\n",
    "      },\n",
    "    ]\n",
    "    optimizer = AdamW(param_dicts, lr=self.lr,\n",
    "    weight_decay=self.weight_decay)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return self.dataloader_train\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return self.dataloader_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detr(dl_train=dataloader_train, dl_eval=dataloader_eval, lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# check output shape [batch x queries x channels]\n",
    "outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask'])\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=NUM_EPOCHS, gradient_clip_val=0.1, accelerator=\"auto\")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.push_to_hub(HF_MODEL, private=True)\n",
    "detr_processor.push_to_hub(HF_MODEL, private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
