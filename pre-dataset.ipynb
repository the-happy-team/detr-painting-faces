{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import IPython.display as ipd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize face images for annotation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SIZE = 384\n",
    "FACES_DIR_IN = \"../metfaces-dataset/images\"\n",
    "FACES_DIR_OUT = \"./dataset/metfaces-faces\"\n",
    "\n",
    "os.makedirs(FACES_DIR_OUT, exist_ok=True)\n",
    "\n",
    "FACES_FILES = [f for f in os.listdir(FACES_DIR_IN) if f.endswith(\".png\")]\n",
    "\n",
    "for f in FACES_FILES:\n",
    "    path_in = os.path.join(FACES_DIR_IN, f)\n",
    "    path_out = os.path.join(FACES_DIR_OUT, f).replace(\".png\", \".jpg\")\n",
    "\n",
    "    if not os.path.isfile(path_out):\n",
    "        with Image.open(path_in) as im:\n",
    "            im.thumbnail((NEW_SIZE, NEW_SIZE))\n",
    "            im.save(path_out, \"JPEG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize unprocessed images and simplify metfaces-dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_rect region is specififed in [x0,y0, x1,y1] not [x,y,w,h]\n",
    "\n",
    "METFACES_PATH = \"../metfaces-dataset\"\n",
    "DATASET_PATH = \"./dataset\"\n",
    "\n",
    "IMG_NEW_SIZE = 800\n",
    "IMGS_DIR_IN = os.path.join(METFACES_PATH, \"unprocessed\")\n",
    "IMGS_DIR_OUT = os.path.join(DATASET_PATH, \"source-metfaces\")\n",
    "\n",
    "JSON_FILEPATH_IN = os.path.join(METFACES_PATH, \"metfaces-dataset.json\")\n",
    "JSON_FILEPATH_OUT = os.path.join(DATASET_PATH, \"metfaces-faces.json\")\n",
    "\n",
    "KEYS_TO_REMOVE = [\n",
    "    \"meta_url\",\n",
    "    \"source_url\",\n",
    "    \"source_md5\",\n",
    "    \"image_md5\",\n",
    "    \"source_path\",\n",
    "    \"image_path\",\n",
    "    \"title\",\n",
    "    \"artist_display_name\",\n",
    "    \"face_spec\",\n",
    "    \"face_idx\"\n",
    "]\n",
    "\n",
    "os.makedirs(IMGS_DIR_OUT, exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(JSON_FILEPATH_OUT):\n",
    "    with open(JSON_FILEPATH_OUT, 'w') as json_file_out_write:\n",
    "        json.dump([], json_file_out_write)\n",
    "\n",
    "out_keys = set()\n",
    "with open(JSON_FILEPATH_OUT) as json_file_out_read:\n",
    "    mfd_out = json.load(json_file_out_read)\n",
    "\n",
    "    for obj in mfd_out:\n",
    "        out_keys.add(obj[\"obj_id\"])\n",
    "\n",
    "try:\n",
    "    with open(JSON_FILEPATH_IN) as json_file_in:\n",
    "        mfd = json.load(json_file_in)\n",
    "\n",
    "        for p_obj in mfd:\n",
    "            img_path_in = os.path.join(METFACES_PATH, p_obj[\"source_path\"])\n",
    "            img_path_out = img_path_in.replace(IMGS_DIR_IN, IMGS_DIR_OUT).replace(\".png\", \".jpg\")\n",
    "            obj_id = str(p_obj[\"image_path\"]).replace(\"images/\", \"\").replace(\".png\", \"\")\n",
    "\n",
    "            if not os.path.isfile(img_path_out) or obj_id not in out_keys:\n",
    "                print(\"processing: \", p_obj[\"source_path\"], obj_id)\n",
    "                with Image.open(img_path_in) as im:\n",
    "                    (in_w, in_h) = im.size\n",
    "                    im.thumbnail((IMG_NEW_SIZE, IMG_NEW_SIZE))\n",
    "                    (out_w, out_h) = im.size\n",
    "                    shrink = out_w / in_w * p_obj[\"face_spec\"][\"shrink\"]\n",
    "                    face_coords = [int(x * shrink) for x in p_obj[\"face_spec\"][\"rect\"]]\n",
    "\n",
    "                    landmarks = (np.float32(p_obj[\"face_spec\"][\"landmarks\"]) + 0.5) * shrink\n",
    "                    lm_eye_left = landmarks[36 : 42]\n",
    "                    lm_eye_right = landmarks[42 : 48]\n",
    "                    eye_left = np.mean(lm_eye_left, axis=0)\n",
    "                    eye_right = np.mean(lm_eye_right, axis=0)\n",
    "                    eye_avg = (eye_left + eye_right) * 0.5\n",
    "\n",
    "                    face_dim = face_coords[2] - face_coords[0]\n",
    "                    face_top = min(face_coords[1], eye_avg[1] - (face_dim / 2))\n",
    "                    face_bottom = max(face_coords[3], eye_avg[1] + (face_dim / 2))\n",
    "\n",
    "                    face_dim_new = face_bottom - face_top\n",
    "                    face_left = eye_avg[0] - (face_dim_new / 2)\n",
    "                    face_right = eye_avg[0] + (face_dim_new / 2)\n",
    "\n",
    "                    p_obj[\"face_rect\"] = [\n",
    "                        int(max(0, face_left)),\n",
    "                        int(max(0, face_top)),\n",
    "                        int(min(out_w, face_right)),\n",
    "                        int(min(out_h, face_bottom))\n",
    "                    ]\n",
    "\n",
    "                    if not os.path.isfile(img_path_out):\n",
    "                        im.save(img_path_out, \"JPEG\")\n",
    "\n",
    "                    p_obj[\"source_image\"] = str(p_obj[\"source_path\"]).replace(\"unprocessed/\", \"\")\n",
    "                    p_obj[\"obj_id\"] = str(p_obj[\"image_path\"]).replace(\"images/\", \"\").replace(\".png\", \"\")\n",
    "\n",
    "                for k in KEYS_TO_REMOVE:\n",
    "                    del p_obj[k]\n",
    "\n",
    "                if p_obj[\"obj_id\"] not in out_keys:\n",
    "                    mfd_out.append(p_obj)\n",
    "                    out_keys.add(p_obj[\"obj_id\"])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception:\\n\", e)\n",
    "\n",
    "finally:\n",
    "    with open(JSON_FILEPATH_OUT, 'w') as json_file_out_write:\n",
    "        json.dump(mfd_out, json_file_out_write)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and re-crop and get json for cordiais faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METFACES_PATH = \"../metfaces-dataset\"\n",
    "CORDIAIS_PATH = \"../cordiais-analysis\"\n",
    "DATASET_PATH = \"./dataset\"\n",
    "\n",
    "IMG_NEW_SIZE = 800\n",
    "IMGS_DIR_IN = os.path.join(CORDIAIS_PATH, \"imgs\", \"00_raw\")\n",
    "IMGS_DIR_OUT = os.path.join(DATASET_PATH, \"source-cordiais\")\n",
    "FACES_DIR_OUT = os.path.join(DATASET_PATH, \"cordiais-faces\")\n",
    "\n",
    "JSON_FILEPATH = os.path.join(DATASET_PATH, \"cordiais-faces.json\")\n",
    "\n",
    "FACE_API_URL = 'https://api-us.faceplusplus.com/facepp/v3/detect'\n",
    "FACE_API_DATA = {\n",
    "    'api_key': os.environ.get('FACEPP_KEY'),\n",
    "    'api_secret': os.environ.get('FACEPP_SECRET'),\n",
    "    'return_attributes': 'facequality'\n",
    "}\n",
    "\n",
    "os.makedirs(IMGS_DIR_OUT, exist_ok=True)\n",
    "os.makedirs(FACES_DIR_OUT, exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(JSON_FILEPATH):\n",
    "    with open(JSON_FILEPATH, 'w') as json_file_out_write:\n",
    "        json.dump([], json_file_out_write)\n",
    "\n",
    "\n",
    "out_keys = set()\n",
    "mfd_out= {}\n",
    "with open(JSON_FILEPATH) as json_file_out_read:\n",
    "    mfd_out = json.load(json_file_out_read)\n",
    "\n",
    "    for obj in mfd_out:\n",
    "        out_keys.add(obj[\"source_image\"])\n",
    "\n",
    "img_files = sorted([f for f in os.listdir(IMGS_DIR_IN) if f.endswith(\".jpg\")])\n",
    "\n",
    "try:\n",
    "    for fn in img_files:\n",
    "        source_image = fn.replace(\"_raw.jpg\", \"\")\n",
    "        img_path_in = os.path.join(IMGS_DIR_IN, fn)\n",
    "        img_path_out = os.path.join(IMGS_DIR_OUT, \"%s.jpg\" % source_image)\n",
    "\n",
    "        if not os.path.isfile(img_path_out) or source_image not in out_keys:\n",
    "            with Image.open(img_path_in) as im:\n",
    "                if im.size[0] > 2048 or im.size[1] > 2048:\n",
    "                    im.thumbnail((2048, 2048))\n",
    "                (in_w, in_h) = im.size\n",
    "\n",
    "                in_img_byte_arr = io.BytesIO()\n",
    "                im.save(in_img_byte_arr, format=im.format)\n",
    "\n",
    "                im.thumbnail((IMG_NEW_SIZE, IMG_NEW_SIZE))\n",
    "                (out_w, out_h) = im.size\n",
    "                shrink = out_w / in_w\n",
    "\n",
    "                if source_image not in out_keys:\n",
    "                    print(\"processing: \", source_image)\n",
    "\n",
    "                    files = { 'image_file': in_img_byte_arr.getvalue() }\n",
    "                    time.sleep(1.25)\n",
    "                    res = requests.post(FACE_API_URL, files=files, data=FACE_API_DATA)\n",
    "                    res_o = json.loads(res.text)\n",
    "\n",
    "                    if not res.ok:\n",
    "                        print(\"not ok: \", res)\n",
    "\n",
    "                    if res.ok and res_o[\"face_num\"] > 0:\n",
    "                        if not os.path.isfile(img_path_out):\n",
    "                            im.save(img_path_out, \"JPEG\")\n",
    "\n",
    "                        for fi, face in enumerate(res_o[\"faces\"]):\n",
    "                            face_num_str = (\"000000%s\" % fi)[-2:]\n",
    "                            face_slug = \"%s-%s\" % (source_image, face_num_str)\n",
    "\n",
    "                            face_rect = face[\"face_rectangle\"]\n",
    "                            face_bottom = face_rect[\"top\"] + face_rect[\"height\"]\n",
    "                            face_width_center = face_rect[\"left\"] + (face_rect[\"width\"] / 2)\n",
    "                            face_top = max(0, int(face_rect[\"top\"] - 0.2 * face_rect[\"height\"]))\n",
    "                            face_dim_delta = (face_bottom - face_top) / 2\n",
    "\n",
    "                            face_left_new = max(0, int(shrink * (face_width_center - face_dim_delta)))\n",
    "                            face_top_new = max(0, int(shrink * face_top))\n",
    "                            face_right_new = min(out_w, int(shrink * (face_width_center + face_dim_delta)))\n",
    "                            face_bottom_new = min(out_h, int(shrink * face_bottom))\n",
    "                            face_region_new = (\n",
    "                                face_left_new,\n",
    "                                face_top_new,\n",
    "                                face_right_new,\n",
    "                                face_bottom_new\n",
    "                            )\n",
    "\n",
    "                            out_obj = {\n",
    "                                \"source_image\": source_image,\n",
    "                                \"obj_id\": face_slug,\n",
    "                                \"face_rect\": list(face_region_new)\n",
    "                            }\n",
    "\n",
    "                            faces_path_out = os.path.join(FACES_DIR_OUT, \"%s.jpg\" % face_slug)\n",
    "\n",
    "                            if not os.path.isfile(faces_path_out):\n",
    "                                im_crop = im.crop(face_region_new)\n",
    "                                im_crop.save(faces_path_out, \"JPEG\")\n",
    "\n",
    "                            mfd_out.append(out_obj)\n",
    "            \n",
    "                        out_keys.add(source_image)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Exception:\\n\", e)\n",
    "\n",
    "finally:\n",
    "    with open(JSON_FILEPATH, 'w') as json_file_out_write:\n",
    "        json.dump(mfd_out, json_file_out_write)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterate through jsons and annotate genre: F / NOTFEMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./dataset\"\n",
    "sets = [\"cordiais\", \"metfaces\"]\n",
    "\n",
    "for set in sets:\n",
    "    json_file_path = os.path.join(DATASET_PATH, \"%s-faces.json\" % set)\n",
    "\n",
    "    faces = []\n",
    "    with open(json_file_path) as json_file_read:\n",
    "        faces = json.load(json_file_read)\n",
    "\n",
    "    for face in faces:\n",
    "        if \"gender\" not in face:\n",
    "            painting_path = os.path.join(DATASET_PATH, \"source-%s\" % set, \"%s.jpg\" % face[\"source_image\"])\n",
    "            face_path = os.path.join(DATASET_PATH, \"%s-faces\" % set, \"%s.jpg\" % face[\"obj_id\"])\n",
    "\n",
    "            painting_html = \"<td><img src='%s' height=300></td>\" % painting_path\n",
    "            face_html = \"<td><img src='%s' height=300></td>\" % face_path\n",
    "\n",
    "            html_string = \"<table><tr>%s %s</tr></table>\" % (painting_html, face_html)\n",
    "            ipd.display(ipd.HTML(html_string), clear=True)\n",
    "\n",
    "            key = input()\n",
    "            if key == \"f\":\n",
    "                face[\"gender\"] = \"female\"\n",
    "            elif key == \"s\" or key == \"q\":\n",
    "                with open(json_file_path, 'w') as json_file_out_write:\n",
    "                    json.dump(faces, json_file_out_write)\n",
    "            else:\n",
    "                face[\"gender\"] = \"notfemale\"\n",
    "\n",
    "            if key == \"q\":\n",
    "                break\n",
    "\n",
    "    with open(json_file_path, 'w') as json_file_out_write:\n",
    "        json.dump(faces, json_file_out_write)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
