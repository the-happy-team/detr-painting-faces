{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.ops import box_iou\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "from Cocordiais import CocordiaisDataset, CocordiaisUtils\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_DATASET = \"thiagohersan/cordiais-faces\"\n",
    "DETR_MODEL = \"facebook/detr-resnet-50\"\n",
    "\n",
    "detr_size = { \"shortest_edge\": 800, \"longest_edge\": 800 }\n",
    "detr_processor = DetrImageProcessor.from_pretrained(DETR_MODEL, size=detr_size)\n",
    "\n",
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset_train = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "dataset = {\n",
    "  \"eval\": {\n",
    "    \"images\": hf_dataset_train[\"test\"][\"image\"],\n",
    "    \"data\": CocordiaisDataset(hf_dataset_train[\"test\"], img_processor=detr_processor, train=False).data\n",
    "  },\n",
    "  \"test\": {\n",
    "    \"images\": hf_dataset[\"test\"][\"image\"],\n",
    "    \"data\": CocordiaisDataset(hf_dataset[\"test\"], img_processor=detr_processor, train=False).data\n",
    "  }\n",
    "}\n",
    "\n",
    "print(\n",
    "  f\"Number of examples:\\n\"\n",
    "  f\"  Evaluation: {len(dataset['eval']['data'])}\\n\"\n",
    "  f\"  Test: {len(dataset['test']['data'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes_xyxy(labels):\n",
    "  ih, iw = tuple(labels[\"orig_size\"])\n",
    "  bboxes_xyxy = []\n",
    "  for (xc, yc, bw, bh) in labels[\"boxes\"]:\n",
    "    bboxes_xyxy.append([\n",
    "      (xc - bw / 2) * iw,\n",
    "      (yc - bh / 2) * ih,\n",
    "      (xc + bw / 2) * iw,\n",
    "      (yc + bh / 2) * ih\n",
    "    ])\n",
    "  return torch.tensor(bboxes_xyxy)\n",
    "\n",
    "def top_label_error(expected, estimated):\n",
    "  if len(estimated[\"scores\"]) < 1:\n",
    "    return 1\n",
    "\n",
    "  top_score_idx = estimated[\"scores\"].argmax()\n",
    "  top_score_label = estimated[\"labels\"][top_score_idx]\n",
    "  top_score_box = estimated[\"boxes\"][top_score_idx]\n",
    "\n",
    "  biou = box_iou(top_score_box.unsqueeze(0), expected[\"boxes\"])\n",
    "  biou_max_idx = biou.argmax()\n",
    "  biou_max_label = expected[\"labels\"][biou_max_idx]\n",
    "\n",
    "  return (top_score_label != biou_max_label).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_COLORS = [\n",
    "  [0.494, 0.184, 0.556], [0.929, 0.694, 0.125]\n",
    "]\n",
    "\n",
    "def plot_results(pil_img, results):\n",
    "  scores = results[\"scores\"]\n",
    "  labels = results[\"labels\"]\n",
    "  boxes = results[\"boxes\"]\n",
    "\n",
    "  plt.figure(figsize=(16,10))\n",
    "  plt.imshow(pil_img)\n",
    "  ax = plt.gca()\n",
    "\n",
    "  for score, label, (xmin, ymin, xmax, ymax) in zip(scores.tolist(), labels.tolist(), boxes.tolist()):\n",
    "    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=PLOT_COLORS[label], linewidth=3))\n",
    "    text = f'{CocordiaisUtils.ID2LABEL[label]}: {score:0.2f}'\n",
    "    ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = [\n",
    "  \"detr-cordiais-no-aug-48\",\n",
    "  \"detr-cordiais-aug-48\",\n",
    "  \"detr-cordiais-no-aug-64\",\n",
    "  \"detr-cordiais-aug-64\",\n",
    "  \"detr-cordiais-no-aug-100\",\n",
    "  \"detr-cordiais-aug-100\",\n",
    "  \"detr-cordiais-aug1-100\",\n",
    "  \"detr-cordiais-aug1-100-no_norm\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "  hf_model = f\"thiagohersan/{model_name}\"\n",
    "  detr_model = DetrForObjectDetection.from_pretrained(hf_model, id2label=CocordiaisUtils.ID2LABEL)\n",
    "  detr_model = detr_model.to(device)\n",
    "\n",
    "  for split in [\"eval\", \"test\"]:\n",
    "    model_eval = {}\n",
    "\n",
    "    for data_idx, data in enumerate(dataset[split][\"data\"]):\n",
    "      pixel_values, pixel_mask, labels = data.values()\n",
    "      pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "      pixel_mask = pixel_mask.unsqueeze(0).to(device)\n",
    "      labels = [{k: v.to(device) for k, v in labels.items()}]\n",
    "\n",
    "      with torch.no_grad():\n",
    "        outputs = detr_model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "      loss = outputs.loss\n",
    "      loss_dict = outputs.loss_dict\n",
    "\n",
    "      model_eval[\"loss\"] = model_eval.get(\"loss\", 0) + loss.item()\n",
    "      for k,v in loss_dict.items():\n",
    "        model_eval[k] = model_eval.get(k, 0) + v.item()\n",
    "\n",
    "      orig_h, orig_w = labels[0][\"orig_size\"].tolist()\n",
    "      estimated = detr_processor.post_process_object_detection(\n",
    "        outputs,\n",
    "        target_sizes=[(orig_h, orig_w)],\n",
    "        threshold=0.5\n",
    "      )\n",
    "\n",
    "      expected = [{\n",
    "        \"labels\": labels[0][\"class_labels\"],\n",
    "        \"boxes\": get_bboxes_xyxy(labels[0])\n",
    "      }]\n",
    "\n",
    "      model_eval[\"label_error\"] = model_eval.get(\"label_error\", 0) + top_label_error(expected[0], estimated[0])\n",
    "      model_eval[\"samples\"] = model_eval.get(\"samples\", 0) + 1\n",
    "\n",
    "      # image = ToPILImage()(pixel_values.squeeze())\n",
    "      # image = dataset[split][\"images\"][data_idx]\n",
    "      # plot_results(image, estimated[0])\n",
    "      # plot_results(image, expected[0])\n",
    "\n",
    "    for k, v in model_eval.items():\n",
    "      if k != \"samples\":\n",
    "        model_eval[k] = round(v / model_eval[\"samples\"], 4)\n",
    "    model_eval[\"split\"] = split\n",
    "    model_eval[\"model\"] = model_name.replace(\"detr-cordiais-\", \"\")\n",
    "\n",
    "    metrics.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fieldnames = list(metrics[0].keys())\n",
    "\n",
    "with open('metrics.csv', 'w', newline='') as metrics_csv:\n",
    "  writer = csv.DictWriter(metrics_csv, fieldnames=fieldnames)\n",
    "  writer.writeheader()\n",
    "  for m in metrics:\n",
    "    writer.writerow(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
