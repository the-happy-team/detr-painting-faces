{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import ToPILImage\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "from Cocordiais import CocordiaisDataset, CocordiaisUtils\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = [\n",
    "  \"detr-cordiais-no-aug-48\",\n",
    "  \"detr-cordiais-aug-48\",\n",
    "  \"detr-cordiais-aug-64\",\n",
    "  \"detr-cordiais-no-aug-100\",\n",
    "  \"detr-cordiais-aug-100\"\n",
    "]\n",
    "\n",
    "HF_MODEL= f\"thiagohersan/{MODEL_NAMES[0]}\"\n",
    "\n",
    "HF_DATASET = \"thiagohersan/cordiais-faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "detr_model = DetrForObjectDetection.from_pretrained(HF_MODEL, id2label=CocordiaisUtils.ID2LABEL)\n",
    "detr_processor = DetrImageProcessor.from_pretrained(HF_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset_train = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "dataset_test = CocordiaisDataset(hf_dataset[\"test\"], img_processor=detr_processor, train=False)\n",
    "dataset_eval = CocordiaisDataset(hf_dataset_train[\"test\"], img_processor=detr_processor, train=False)\n",
    "\n",
    "print(\"Number of examples:\\n  Test: %s\\n  Evaluation: %s\" % (len(dataset_test), len(dataset_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_COLORS = [\n",
    "  [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "  [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "def plot_results(pil_img, results):\n",
    "  scores = results[\"scores\"]\n",
    "  labels = results[\"labels\"]\n",
    "  boxes = results[\"boxes\"]\n",
    "\n",
    "  plt.figure(figsize=(16,10))\n",
    "  plt.imshow(pil_img)\n",
    "  ax = plt.gca()\n",
    "  colors = PLOT_COLORS * 100\n",
    "  for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=c, linewidth=3))\n",
    "    text = f'{CocordiaisUtils.ID2LABEL[label]}: {score:0.2f}'\n",
    "    ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 20\n",
    "pixel_values, pixel_mask, labels = dataset_eval.data[data_idx].values()\n",
    "pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_model.to(device)\n",
    "with torch.no_grad():\n",
    "  outputs = detr_model(pixel_values=pixel_values, pixel_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = labels[\"image_id\"].item()\n",
    "image = ToPILImage()(pixel_values.squeeze())\n",
    "\n",
    "width, height = image.size\n",
    "results = detr_processor.post_process_object_detection(\n",
    "  outputs,\n",
    "  target_sizes=[(height, width)],\n",
    "  threshold=0.5\n",
    ")\n",
    "plot_results(image, results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
