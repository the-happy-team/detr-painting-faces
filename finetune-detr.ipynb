{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune DETR to detect female-ish faces in paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers datasets huggingface_hub pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from transformers import AutoModelForObjectDetection, DetrImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETR_CHECKPOINT = \"facebook/detr-resnet-50\"\n",
    "HF_DATASET = \"thiagohersan/cordiais-faces\"\n",
    "HF_MODEL= \"thiagohersan/detr-cordiais\"\n",
    "\n",
    "detr_processor = DetrImageProcessor.from_pretrained(\n",
    "  DETR_CHECKPOINT,\n",
    "  size={\n",
    "    \"shortest_edge\": 800,\n",
    "    \"longest_edge\": 800\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_coco_annotation(image_id, category, area, bbox):\n",
    "  annotations = []\n",
    "  for i in range(0, len(category)):\n",
    "    new_ann = {\n",
    "      \"image_id\": image_id,\n",
    "      \"category_id\": category[i],\n",
    "      \"isCrowd\": 0,\n",
    "      \"area\": area[i],\n",
    "      \"bbox\": list(bbox[i]),\n",
    "    }\n",
    "    annotations.append(new_ann)\n",
    "\n",
    "  return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detr_annotate_augment_process(examples):\n",
    "  image_ids = examples[\"image_id\"]\n",
    "  images, bboxes, area, categories = [], [], [], []\n",
    "  for image, objects in zip(examples[\"image\"], examples[\"objects\"]):\n",
    "    # TODO: augment here\n",
    "    area.append(objects[\"area\"])\n",
    "    images.append(image)\n",
    "    bboxes.append(objects[\"bboxes\"])\n",
    "    categories.append(objects[\"category\"])\n",
    "\n",
    "  targets = [\n",
    "    {\"image_id\": id_, \"annotations\": to_coco_annotation(id_, cat_, ar_, box_)}\n",
    "    for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)\n",
    "  ]\n",
    "\n",
    "  return detr_processor(images=images, annotations=targets, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_ = datasets.load_dataset(HF_DATASET).with_transform(detr_annotate_augment_process)\n",
    "hf_dataset = hf_dataset_[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hf_dataset[\"train\"].features[\"objects\"].feature[\"category\"].names\n",
    "id2label = {i:l for i,l in enumerate(labels)}\n",
    "label2id = {l:i for i,l in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "  encoding = detr_processor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "  labels = [item[\"labels\"] for item in batch]\n",
    "  batch = {}\n",
    "  batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "  batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "  batch[\"labels\"] = labels\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "  DETR_CHECKPOINT,\n",
    "  id2label=id2label,\n",
    "  label2id=label2id,\n",
    "  revision=\"no_timm\", \n",
    "  num_labels=len(id2label),\n",
    "  num_queries=16,\n",
    "  ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"detr-resnet-50_finetuned_cordiais\",\n",
    "  per_device_train_batch_size=4,\n",
    "  num_train_epochs=32,\n",
    "  fp16=True,\n",
    "  save_steps=200,\n",
    "  logging_steps=50,\n",
    "  learning_rate=1e-5,\n",
    "  weight_decay=1e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  data_collator=collate_fn,\n",
    "  train_dataset=hf_dataset[\"train\"],\n",
    "  tokenizer=detr_processor\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "id2label = { 0: \"female\", 1: \"not-female\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DetrForObjectDetection.from_pretrained(HF_MODEL, id2label=id2label)\n",
    "processor = DetrImageProcessor.from_pretrained(HF_MODEL)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\n",
    "  [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "  [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "def plot_results(pil_img, scores, labels, boxes, id2label):\n",
    "  plt.figure(figsize=(16,10))\n",
    "  plt.imshow(pil_img)\n",
    "  ax = plt.gca()\n",
    "  colors = COLORS * 100\n",
    "  for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=c, linewidth=3))\n",
    "    text = f'{id2label[label]}: {score:0.2f}'\n",
    "    ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  plt.savefig(\"out.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values, target = test_dataset[0]\n",
    "pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "  outputs = model(pixel_values=pixel_values, pixel_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = target[\"image_id\"].item()\n",
    "image = test_dataset.coco.loadImgs(image_id)[0]\n",
    "image = PImage.open(os.path.join(COCORDIAIS_PATH, \"test\", image[\"file_name\"]))\n",
    "\n",
    "width, height = image.size\n",
    "postprocessed_outputs = processor.post_process_object_detection(\n",
    "  outputs,\n",
    "  target_sizes=[(height, width)],\n",
    "  threshold=0.5\n",
    ")\n",
    "\n",
    "results = postprocessed_outputs[0]\n",
    "plot_results(image, results[\"scores\"], results[\"labels\"], results[\"boxes\"], id2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
