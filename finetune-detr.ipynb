{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune DETR to detect female-ish faces in paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade scipy transformers datasets huggingface_hub pytorch-lightning pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForObjectDetection, DetrImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "from Cocordiais import CocordiaisData\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETR_MODEL = \"facebook/detr-resnet-50\"\n",
    "HF_DATASET = \"thiagohersan/cordiais-faces\"\n",
    "HF_MODEL= \"thiagohersan/detr-cordiais-autotrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_processor = DetrImageProcessor.from_pretrained(\n",
    "  DETR_MODEL,\n",
    "  size={\n",
    "    \"shortest_edge\": 800,\n",
    "    \"longest_edge\": 800\n",
    "  }\n",
    ")\n",
    "\n",
    "cocordiais_data = CocordiaisData(detr_processor)\n",
    "\n",
    "hf_dataset = datasets.load_dataset(HF_DATASET)\n",
    "hf_dataset = hf_dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=101010)\n",
    "\n",
    "train_dataset = hf_dataset[\"train\"].with_transform(cocordiais_data.to_coco(train=True))\n",
    "test_dataset = hf_dataset[\"test\"].with_transform(cocordiais_data.to_coco(train=False))\n",
    "\n",
    "print(\"Number of examples:\\n  Train: %s\\n  Test: %s\" % (len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_dataset.features[\"objects\"].feature[\"category\"].names\n",
    "id2label = {i:l for i,l in enumerate(labels)}\n",
    "label2id = {l:i for i,l in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "  DETR_MODEL,\n",
    "  id2label=id2label,\n",
    "  label2id=label2id,\n",
    "  revision=\"no_timm\", \n",
    "  num_labels=len(id2label),\n",
    "  num_queries=16,\n",
    "  ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=HF_MODEL,\n",
    "  per_device_train_batch_size=12,\n",
    "  per_device_eval_batch_size=4,\n",
    "  num_train_epochs=48,\n",
    "  fp16=True,\n",
    "  save_strategy=\"epoch\",\n",
    "  save_total_limit=2,\n",
    "  logging_strategy=\"epoch\",\n",
    "  learning_rate=1e-5,\n",
    "  weight_decay=1e-4,\n",
    "  remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  data_collator=cocordiais_data.collate_batch,\n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=test_dataset,\n",
    "  tokenizer=detr_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(HF_MODEL, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "id2label = { 0: \"female\", 1: \"not-female\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DetrForObjectDetection.from_pretrained(HF_MODEL, id2label=id2label)\n",
    "processor = DetrImageProcessor.from_pretrained(HF_MODEL)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\n",
    "  [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "  [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "def plot_results(pil_img, scores, labels, boxes, id2label):\n",
    "  plt.figure(figsize=(16,10))\n",
    "  plt.imshow(pil_img)\n",
    "  ax = plt.gca()\n",
    "  colors = COLORS * 100\n",
    "  for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=c, linewidth=3))\n",
    "    text = f'{id2label[label]}: {score:0.2f}'\n",
    "    ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  plt.savefig(\"out.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values, target = test_dataset[0]\n",
    "pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "  outputs = model(pixel_values=pixel_values, pixel_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = target[\"image_id\"].item()\n",
    "image = test_dataset.coco.loadImgs(image_id)[0]\n",
    "image = PImage.open(os.path.join(COCORDIAIS_PATH, \"test\", image[\"file_name\"]))\n",
    "\n",
    "width, height = image.size\n",
    "postprocessed_outputs = processor.post_process_object_detection(\n",
    "  outputs,\n",
    "  target_sizes=[(height, width)],\n",
    "  threshold=0.5\n",
    ")\n",
    "\n",
    "results = postprocessed_outputs[0]\n",
    "plot_results(image, results[\"scores\"], results[\"labels\"], results[\"boxes\"], id2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
